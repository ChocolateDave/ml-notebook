{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Variational Gaussian Process Classification\n",
    "\n",
    "@Author Juanwu Lu\n",
    "\n",
    "@Date   Mar-2-2023\n",
    "\n",
    "The scalable Gaussian Process Classifier model using Stochastic Variantional inference was first introduced by J. Hensman, et al. in the paper [Scalable Variational Gaussian Process Classifier](https://arxiv.org/pdf/1411.2005.pdf)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "Related topics to the proposed SVGPC model in the original papers are **Guanssian Process Classification** and **Sparse Gaussian Processes for Regression**. As mentioned in the paper introduction, although sharing some common addresses, the two area seldomly overlap.\n",
    "\n",
    "### Gaussian Process Classification\n",
    "\n",
    "First, let's consider the simplest case - binary classification. If denote the binary class labels by $\\mathbf{y}=\\left\\{y_n\\right\\}_{n=1}^N$, and then collect the input data into a design matrix $\\mathbf{X}=\\left\\{\\mathbf{x}_n\\right\\}_{n=1}^N$. The covariance matrix is evaluated at all pairs of input vectors, and arrive at a zero-mean prior for the values of the GP function at the input points $p(\\mathbf{f})=\\mathcal{N}(\\mathbf{f}\\mid\\mathbf{0},\\mathbf{K}_{nn})$.\n",
    "\n",
    "To perform binary classfication on the Gaussian prior, we **squash** the prior using a *sigmoidal inverse link function* $\\phi(x)=\\int\\limits_{-\\infty}^x\\mathcal{N}(a\\mid 0, 1)da$, and a Bernoulli likelihood $\\mathscr{B}(y_n\\mid\\phi(f_n))=\\phi(f_n)^{y_n}\\left(1-\\phi(f_n)\\right)^{1-y_n}$ to condition the data on the transformed function values. Following the assumption that **data are independent identical distributed (i.i.d)**, we have the joint distribution given by\n",
    "$$\n",
    "    p(\\mathbf{y},\\mathbf{f})=\\prod\\limits_{n=1}^N\\mathcal{B}(y_n\\mid\\phi(f_n))\\mathcal{N}(\\mathbf{f}\\mid\\mathbf{0},\\mathbf{K}_{nn}).\n",
    "$$\n",
    "\n",
    "As a result, the problem will now be to learn the posterior over the function values given by $p(\\mathbf{f}\\mid\\mathbf{y})$. The challenge is that the matrix inverse computation here often requires $\\mathscr{O}(N^3)$ computation for a dataset of size $N$.\n",
    "\n",
    "### Sparse Gaussian Processes for Regression\n",
    "\n",
    "One way to tackle the computation burden is by inducing additional input-output paris $\\mathbf{Z}$ and $\\mathbf{u}$, known as 'inducing inputs' and 'inducing variables'. Then the joint distrbution of $\\mathbf{f}$ and $\\mathbf{u}$ is given by\n",
    "$$\n",
    "    p(\\mathbf{f}, \\mathbf{u})=\\mathcal{N}\\left(\\begin{bmatrix}\\mathbf{f} \\\\ \\mathbf{u}\\end{bmatrix}\\mid\\mathbf{0},\\begin{bmatrix}\\mathbf{K}_{nn} & \\mathbf{K}_{nm} \\\\ \\mathbf{K}_{nm}^\\intercal & \\mathbf{K}_{mm}\\end{bmatrix}\\right),\n",
    "$$\n",
    "where $\\mathbf{K}_{mm}$ is formed by evaluting the covariance function at *all pairs of inducing input points $\\mathbf{z}_m,\\mathbf{z}_m$. Using the property of conditional distribution on bivariate Gaussian, we have\n",
    "$$\n",
    "    \\mathbf{f}\\mid\\mathbf{u}\\sim\\mathcal{N}\\left(\\mathbf{0}+\\mathbf{K}_{nm}\\mathbf{K}_{mm}^{-1}(\\mathbf{u}-\\mathbf{0}), \\mathbf{K}_{nn}-\\mathbf{K}_{nm}\\mathbf{K}_{mm}^{-1}\\mathbf{K}_{nm}^\\intercal\\right),\\quad \\mathbf{u}\\sim\\mathbf{N}(0,\\mathbf{K}_{mm}),\n",
    "$$\n",
    "and the joint distribution of $\\mathbf{y}$, $\\mathbf{f}$, $\\mathbf{u}$ takes the form\n",
    "$$\n",
    "    p(\\mathbf{y},\\mathbf{f},\\mathbf{u})=p(\\mathbf{y}\\mid\\mathbf{f})p(\\mathbf{f}\\mid\\mathbf{u})p(\\mathbf{u}).\n",
    "$$\n",
    "As a result, the computation bottle neck $\\mathscr{O}(N^3)$ is now reduced to $\\mathscr{O}(M^3)$ where $M$ is the number of inducing points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import os\n",
    "import zipfile\n",
    "from urllib import request\n",
    "\n",
    "import gpytorch\n",
    "from scipy.io.arff import loadarff\n",
    "import torch\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our experiments, we test the Gaussian Process model on the [Polish Company Bankruptcy Dataset](https://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the polish bankruptcy data set\n",
    "if not os.path.isdir('../data/polish_bankruptcy'):\n",
    "    os.makedirs('../data/polish_bankruptcy', exist_ok=True)\n",
    "\n",
    "if not os.path.isfile('../data/polish_bankruptcy/data.zip'):\n",
    "    request.urlretrieve(\n",
    "        url='https://archive.ics.uci.edu/ml/' +\n",
    "        'machine-learning-databases/00365/data.zip',\n",
    "        filename='../data/polish_bankruptcy/data.zip'\n",
    "    )\n",
    "\n",
    "# Validate that all the dataset files exist\n",
    "for i in range(1, 6):\n",
    "    if not os.path.exists(f'../data/polish_bankruptcy/{i:d}year.arff'):\n",
    "        with zipfile.ZipFile(\n",
    "            '../data/polish_bankruptcy/data.zip', 'r'\n",
    "        ) as zip_ref:\n",
    "            zip_ref.extractall('../data/polish_bankruptcy/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
